{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AAAI ICWSM 2024 | Tutorial | June 3rd | 2-6pm\n",
        "## <u>Collectivist and Perspectivist Approaches to Studying Online Toxicity</u>\n",
        "### Yotam Shmargad, School of Government & Public Policy, University of Arizona"
      ],
      "metadata": {
        "id": "N5z7rpKxmE8y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### This is the <b>second</b> of two notebooks we will discuss during the tutorial. The notebook is written in Python and walks participants through analyzing YouTube comments from a *Perspectivist* approach. The notebook:\n",
        "1.   Collects YouTube videos for <b>two</b> separate queries\n",
        "2.   Collects comments AND replies for videos from each query and organizes data into comment-reply pairs\n",
        "3.   Analyzes *hatefulness* in the two sets of comments and replies\n",
        "4.   Compares the two sets in how hate in comments *(descriptive norm)* is associated with hate in replies\n",
        "5.   Compares the two sets in how hate *(descriptive norm)* and like counts *(injunctive norm)* of comments <b>interact</b> in their association with hate in replies (i.e., Theory of Normative Social Behavior)"
      ],
      "metadata": {
        "id": "Ba_sJsLsmJFf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Collect YouTube videos for <b>two</b> separate queries`"
      ],
      "metadata": {
        "id": "IPT8WYwlnGg8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FjE7LCEl9vk"
      },
      "outputs": [],
      "source": [
        "# Install library for YouTube data collection https://youtube-data-api.readthedocs.io/en/latest/youtube_api.html\n",
        "!pip install youtube-data-api"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries for data collection, management, and analysis\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from youtube_api import YouTubeDataAPI\n",
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "J-PqeMZxmDXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain API Key from https://console.cloud.google.com/apis/\n",
        "# Authenticate with YouTube - place the API Key you obtained between the quotes\n",
        "yt = YouTubeDataAPI(\"\")"
      ],
      "metadata": {
        "id": "-z7LjDuvnM5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect 100 videos using a query search - place your search term between the quotes\n",
        "vids1 = yt.search(\"trump\",max_results = 50)"
      ],
      "metadata": {
        "id": "kjtvAq8e_jmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect 100 videos using a different query\n",
        "vids2 = yt.search(\"biden\",max_results = 50)"
      ],
      "metadata": {
        "id": "nlDmQNfp_o6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print number of videos collected for each query\n",
        "print(\"Query 1:\",len(vids1))\n",
        "print(\"Query 2:\",len(vids2))"
      ],
      "metadata": {
        "id": "nPhkPubS_r9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Collect comments AND replies for videos from each query and organize data into comment-reply pairs"
      ],
      "metadata": {
        "id": "-anMR7ImjpSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve 500 comments for the ith video from second query\n",
        "com = yt.get_video_comments(vids2[i]['video_id'],get_replies = True,max_results = 500)"
      ],
      "metadata": {
        "id": "RrsRQ-ro__i3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Place comment data into a pandas table\n",
        "com_df = pd.DataFrame(com)"
      ],
      "metadata": {
        "id": "RzcjUQuKkveM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print columns that have a period (.) in the comment_id, which indicates a reply\n",
        "com_df[com_df['comment_id'].str.contains('.', regex=False)]"
      ],
      "metadata": {
        "id": "Gk2jDt5mtOVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Subset comments to two different dataframes: 1) popular comments and 2) replies\n",
        "pop_df = com_df[com_df['reply_count'] > 0]\n",
        "rep_df = com_df[com_df['comment_parent_id'].isnull()==False]"
      ],
      "metadata": {
        "id": "vjMg2y9PMQv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print dimensions of comment df, popular comment df, and reply df\n",
        "print(\"All comments:\",com_df.shape)\n",
        "print(\"Popular comments:\",pop_df.shape)\n",
        "print(\"Replies:\",rep_df.shape)"
      ],
      "metadata": {
        "id": "NQrQl2MRnpB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract relevant columns from new dataframes\n",
        "small_pop_df = pop_df[['video_id','comment_id','comment_like_count','text']]\n",
        "small_rep_df = rep_df[['video_id','comment_parent_id','comment_like_count','text']]"
      ],
      "metadata": {
        "id": "fHFSjtM0KTi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the two dataframes so that data about comments and their replies are in the same row\n",
        "mer_df = pd.merge(small_pop_df,small_rep_df,left_on='comment_id', right_on='comment_parent_id', how='inner', suffixes=('_com', '_rep'))"
      ],
      "metadata": {
        "id": "DMZ1kuxhJuck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print merged dataframe\n",
        "mer_df"
      ],
      "metadata": {
        "id": "GmpOj2dtIhFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print dimensions of merged dataframe\n",
        "mer_df.shape"
      ],
      "metadata": {
        "id": "KkHRsq1C5GX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define empty table for storing comment-reply pairs from videos in first query\n",
        "comreps1 = pd.DataFrame(columns=['video_id_com','comment_id','comment_like_count_com', 'text_com','video_id_rep','comment_parent_id','comment_like_count_rep','text_rep'])"
      ],
      "metadata": {
        "id": "jbF2zHO0JdH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through videos from first query, pull 500 comments per video, organize into comment-reply pairs, and append them to a single table\n",
        "for i in vids1:\n",
        "  try:\n",
        "    c = yt.get_video_comments(i['video_id'],get_replies = True,max_results = 500)\n",
        "    cdf = pd.DataFrame(c)\n",
        "    pdf = cdf[cdf['reply_count'] > 0]\n",
        "    rdf = cdf[cdf['comment_parent_id'].isnull()==False]\n",
        "    spdf = pdf[['video_id','comment_id','comment_like_count','text']]\n",
        "    srdf = rdf[['video_id','comment_parent_id','comment_like_count','text']]\n",
        "    mdf = pd.merge(spdf,srdf,left_on='comment_id', right_on='comment_parent_id', how='inner', suffixes=('_com', '_rep'))\n",
        "    comreps1 = pd.concat([comreps1,mdf],ignore_index=True)\n",
        "    print(i['video_id'],'success!',mdf.shape[0])\n",
        "  except:\n",
        "    print(i['video_id'],'fail')"
      ],
      "metadata": {
        "id": "-DtWwSkzC5ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print dimensions of comment-reply table for first query\n",
        "comreps1.shape"
      ],
      "metadata": {
        "id": "sNypvM3F3SC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define empty table for storing comment-reply pairs from videos in second query\n",
        "comreps2 = pd.DataFrame(columns=['video_id_com','comment_id','comment_like_count_com', 'text_com','video_id_rep','comment_parent_id','comment_like_count_rep','text_rep'])"
      ],
      "metadata": {
        "id": "64fbMyVJy7Sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through videos from second query, pull 500 comments per video, organize into comment-reply pairs, and append them to a single table\n",
        "for i in vids2:\n",
        "  try:\n",
        "    c = yt.get_video_comments(i['video_id'],get_replies = True,max_results = 500)\n",
        "    cdf = pd.DataFrame(c)\n",
        "    pdf = cdf[cdf['reply_count'] > 0]\n",
        "    rdf = cdf[cdf['comment_parent_id'].isnull()==False]\n",
        "    spdf = pdf[['video_id','comment_id','comment_like_count','text']]\n",
        "    srdf = rdf[['video_id','comment_parent_id','comment_like_count','text']]\n",
        "    mdf = pd.merge(spdf,srdf,left_on='comment_id', right_on='comment_parent_id', how='inner', suffixes=('_com', '_rep'))\n",
        "    comreps2 = pd.concat([comreps2,mdf],ignore_index=True)\n",
        "    print(i['video_id'],'success!',mdf.shape[0])\n",
        "  except:\n",
        "    print(i['video_id'],'fail')"
      ],
      "metadata": {
        "id": "zn3w-YVqy_e0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print dimensions of comment-reply table for second query\n",
        "comreps2.shape"
      ],
      "metadata": {
        "id": "A0KYG3eKYS1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Analyze *hatefulness* in the two sets of comments and replies"
      ],
      "metadata": {
        "id": "Ijbxsse0ZBT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install library for hatefulness analysis https://github.com/pysentimiento/pysentimiento\n",
        "!pip install pysentimiento"
      ],
      "metadata": {
        "id": "U76j72fpZCPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import library for text analysis\n",
        "from pysentimiento import create_analyzer"
      ],
      "metadata": {
        "id": "1EE_5bJIyMfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load hatefulness analyzer in English\n",
        "hate = create_analyzer(task=\"hate_speech\",lang=\"en\")"
      ],
      "metadata": {
        "id": "5Bdy0eGAyQs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create empty columns to store probabilities of hate for all comments and replies\n",
        "comreps1['hate_com'] = ''\n",
        "comreps1['hate_rep'] = ''\n",
        "comreps2['hate_com'] = ''\n",
        "comreps2['hate_rep'] = ''"
      ],
      "metadata": {
        "id": "LJuaIhB8yUay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print table of comment-reply pairs from first query with added column\n",
        "comreps1"
      ],
      "metadata": {
        "id": "zqb0uxe9yq8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize object to store comment_id of previous comment in first query\n",
        "lastcom1 = 'abcdefg'"
      ],
      "metadata": {
        "id": "XSO7xF1U0MbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through comments and replies of first query, analyze for hatefulness, then place scores in the table\n",
        "# NOTE: this may take several minutes to complete\n",
        "for index,row in comreps1.iterrows():\n",
        "  if(row['comment_id'] != lastcom1):\n",
        "    h_com = hate.predict(row['text_com'])\n",
        "    comreps1.at[index, 'hate_com'] = h_com.probas['hateful']\n",
        "    lastcom1 = row['comment_id']\n",
        "  else:\n",
        "    comreps1.at[index, 'hate_com'] = h_com.probas['hateful']\n",
        "  h_rep = hate.predict(row['text_rep'])\n",
        "  comreps1.at[index, 'hate_rep'] = h_rep.probas['hateful']\n",
        "  if((index + 1) % 50 == 0):\n",
        "    print(index + 1,end=\" \")"
      ],
      "metadata": {
        "id": "7vy1vL5DycQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print comments, replies, and hatefulness probabilities for first query\n",
        "comreps1"
      ],
      "metadata": {
        "id": "dGRi64eD1lf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize object to store comment_id of previous comment in second query\n",
        "lastcom2 = 'abcdefg'"
      ],
      "metadata": {
        "id": "NPff069y2fSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through comments and replies of second query, analyze for hatefulness, then place scores in the table\n",
        "# NOTE: this may take several minutes to complete\n",
        "for index,row in comreps2.iterrows():\n",
        "  if(row['comment_id'] != lastcom2):\n",
        "    h_com = hate.predict(row['text_com'])\n",
        "    comreps2.at[index, 'hate_com'] = h_com.probas['hateful']\n",
        "    lastcom2 = row['comment_id']\n",
        "  else:\n",
        "    comreps2.at[index, 'hate_com'] = h_com.probas['hateful']\n",
        "  h_rep = hate.predict(row['text_rep'])\n",
        "  comreps2.at[index, 'hate_rep'] = h_rep.probas['hateful']\n",
        "  if((index + 1) % 50 == 0):\n",
        "    print(index + 1,end=\" \")"
      ],
      "metadata": {
        "id": "vwlppM3W2yel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print comments, replies, and hatefulness probabilities for second query\n",
        "comreps2"
      ],
      "metadata": {
        "id": "5-tWPQgE28rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Compare the two sets in how hate in comments *(descriptive norm)* is associated with hate in replies"
      ],
      "metadata": {
        "id": "ttuMTlLw3svN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create columns to store indicator for first/second query\n",
        "comreps1['query'] = 0\n",
        "comreps2['query'] = 1"
      ],
      "metadata": {
        "id": "wSjGtWpE3tnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Append the two tables together\n",
        "all = pd.concat([comreps1,comreps2],ignore_index = True)"
      ],
      "metadata": {
        "id": "rfaKQ10P4FAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print table of comments\n",
        "all"
      ],
      "metadata": {
        "id": "p0bUCtlR4NE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print variable types\n",
        "all.dtypes"
      ],
      "metadata": {
        "id": "lwWZf0fg4PfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert variable types to numbers\n",
        "all['comment_like_count_com'] = all['comment_like_count_com'].astype(int)\n",
        "all['hate_com'] = all['hate_com'].astype(float)\n",
        "all['comment_like_count_rep'] = all['comment_like_count_rep'].astype(int)\n",
        "all['hate_rep'] = all['hate_rep'].astype(float)"
      ],
      "metadata": {
        "id": "8F5Mpgur4Tu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print variable types after changes\n",
        "all.dtypes"
      ],
      "metadata": {
        "id": "vQ8Wx3dK4iQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create binary variables capturing if probability of hatefulness in comments and replies > 50%\n",
        "all['hate_thresh_com'] = all['hate_com'].apply(lambda x: 1 if x > .5 else 0)\n",
        "all['hate_thresh_rep'] = all['hate_rep'].apply(lambda x: 1 if x > .5 else 0)"
      ],
      "metadata": {
        "id": "TxbcwRZt4kMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print number of comment-reply pairs where comment has probability of hatefulness > 50%\n",
        "all.loc[all['hate_thresh_com'] == 1].size"
      ],
      "metadata": {
        "id": "xDqYB5SY4z0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print number of comment-reply pairs where reply has probability of hatefulness > 50%\n",
        "all.loc[all['hate_thresh_rep'] == 1].size"
      ],
      "metadata": {
        "id": "WX0d9kGp4_K0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create column of all 1s to add a constant to the models\n",
        "all['constant'] = 1"
      ],
      "metadata": {
        "id": "Ihx8mk5S5E0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model how comment hate probability is associated with reply hate probability using OLS regression\n",
        "model1 = sm.OLS(all['hate_rep'],all[['hate_com','constant']])"
      ],
      "metadata": {
        "id": "cY_CdU8r7nvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Model 1 results\n",
        "model1.fit().summary()"
      ],
      "metadata": {
        "id": "Ez9EZLcX78MR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model how comment hate prevalence is associated with reply hate prevalence using OLS regression\n",
        "model2 = sm.OLS(all['hate_thresh_rep'],all[['hate_thresh_com','constant']])"
      ],
      "metadata": {
        "id": "ITwWc4948CS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Model 2 results\n",
        "model2.fit().summary()"
      ],
      "metadata": {
        "id": "XWuUFM2-8QLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model how comment hate prevalence is associated with reply hate prevalence using Logit regression\n",
        "model3 = sm.GLM(all['hate_thresh_rep'],all[['hate_thresh_com','constant']],family=sm.families.Binomial())"
      ],
      "metadata": {
        "id": "CcM_066j8f_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Model 3 results\n",
        "model3.fit().summary()"
      ],
      "metadata": {
        "id": "ZP__u03R8q35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create columns capturing the interaction between query and hatefulness of comments\n",
        "all['interaction'] = all['query']*all['hate_com']\n",
        "all['int_thresh'] = all['query']*all['hate_thresh_com']"
      ],
      "metadata": {
        "id": "LBGY9RVf5J8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model how comment-reply hate probability association varies across the two queries using OLS regression\n",
        "model4 = sm.OLS(all['hate_rep'],all[['hate_com','query','interaction','constant']])"
      ],
      "metadata": {
        "id": "BPflfcub6UnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Model 4 results\n",
        "model4.fit().summary()"
      ],
      "metadata": {
        "id": "_xyn9aOB9tg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model how comment-reply hate prevalence association varies across the two queries using Logit regression\n",
        "model5 = sm.GLM(all['hate_thresh_rep'],all[['hate_thresh_com','query','int_thresh','constant']],family=sm.families.Binomial())"
      ],
      "metadata": {
        "id": "OIOUm6Wf9wZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Model 5 results\n",
        "model5.fit().summary()"
      ],
      "metadata": {
        "id": "l0Iq2INx_ppv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Compare the two sets in how hate *(descriptive norm)* and like counts *(injunctive norm)* of comments <b>interact</b> in their association with hate in replies (i.e., Theory of Normative Social Behavior)"
      ],
      "metadata": {
        "id": "09NrggDH-Tyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create columns capturing the interaction between like counts and hatefulness of comments\n",
        "all['tnsb'] = all['comment_like_count_com']*all['hate_com']\n",
        "all['tnsb_thresh'] = all['comment_like_count_com']*all['hate_thresh_com']"
      ],
      "metadata": {
        "id": "GStFrKUg-e_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model how comment-reply hate probability association varies with like counts using OLS regression\n",
        "model6 = sm.OLS(all['hate_rep'],all[['hate_com','comment_like_count_com','tnsb','constant']])"
      ],
      "metadata": {
        "id": "0Zr0WdK9Ank5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Model 6 results\n",
        "model6.fit().summary()"
      ],
      "metadata": {
        "id": "3DspGW_2A56a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model how comment-reply hate prevalence association varies with like counts using Logit regression\n",
        "model7 = sm.GLM(all['hate_thresh_rep'],all[['hate_thresh_com','comment_like_count_com','tnsb_thresh','constant']],family=sm.families.Binomial())"
      ],
      "metadata": {
        "id": "ZZXUIgY7A84_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Model 7 results\n",
        "model7.fit().summary()"
      ],
      "metadata": {
        "id": "tVLiURvRBXqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create column capturing the interaction between query and like counts of comments\n",
        "all['q_like'] = all['comment_like_count_com']*all['query']"
      ],
      "metadata": {
        "id": "cYbas8LiCs8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create columns capturing the TRIPLE interaction between query, like counts, and hatefulness of comments\n",
        "all['tnsb_int'] = all['comment_like_count_com']*all['hate_com']*all['query']\n",
        "all['tnsb_int_thresh'] = all['comment_like_count_com']*all['hate_thresh_com']*all['query']"
      ],
      "metadata": {
        "id": "Zc96QkMKCKFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model how comment-reply hate probability association varies with like counts AND query using OLS regression\n",
        "model8 = sm.OLS(all['hate_rep'],all[['hate_com','comment_like_count_com','query','tnsb','interaction','q_like','tnsb_int','constant']])"
      ],
      "metadata": {
        "id": "f7W-MRKfBdWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Model 8 results\n",
        "model8.fit().summary()"
      ],
      "metadata": {
        "id": "w8NZ1BOmDJZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model how comment-reply hate prevalence association varies with like counts AND query using Logit regression\n",
        "model9 = sm.GLM(all['hate_thresh_rep'],all[['hate_thresh_com','comment_like_count_com','query','tnsb_thresh','int_thresh','q_like','tnsb_int_thresh','constant']],family=sm.families.Binomial())"
      ],
      "metadata": {
        "id": "ZHGInOaADR6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Model 9 results\n",
        "model9.fit().summary()"
      ],
      "metadata": {
        "id": "fQnvKwMwEC_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <u>Additional considerations</u>\n",
        "1.   Comment like counts are skewed --> could transform with logarithm\n",
        "2.   Arbitrary threshold of .5 for hate --> higher numbers (e.g., .6, .9) are sometimes used<br> --> likely need more data\n",
        "3.   Add fixed/random effects for video, comment, and/or authors<br>--> likely need more data"
      ],
      "metadata": {
        "id": "oI7JtkFbEUI7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "msfL8kS4EbM1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}